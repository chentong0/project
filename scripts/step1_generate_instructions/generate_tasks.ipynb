{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(\"../../src\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openai_lm import OpenAIModel\n",
    "from utils.parser import load_prompt, load_jsonl, save_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# prompt_path = \"prompt.txt\"\n",
    "# # passage_path = \"../../outputs/passages.jsonl\"\n",
    "# passage_path = \"../../scripts/download_papers/outputs/paragraphs.jsonl\"\n",
    "\n",
    "# prompt_template = load_prompt(prompt_path)\n",
    "# doc_list = load_jsonl(passage_path)\n",
    "\n",
    "# min_len = 100\n",
    "# max_len = 400\n",
    "\n",
    "# task_list = []\n",
    "\n",
    "# para_list = sum([doc[\"paragraphs\"] for doc in doc_list], [])\n",
    "# para_list = [p for p in para_list if min_len < len(p[\"content\"].split()) < max_len]\n",
    "# print(f\"Number of paragraphs: {len(para_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraphs: 78333\n"
     ]
    }
   ],
   "source": [
    "prompt_path = \"prompt.txt\"\n",
    "para_path = \"../../scripts/download_papers/outputs/paragraphs.jsonl\"\n",
    "\n",
    "prompt_template = load_prompt(prompt_path)\n",
    "para_list = load_jsonl(para_path)\n",
    "\n",
    "print(f\"Number of paragraphs: {len(para_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI, I do not have feelings or emotions, but I am here to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from utils.openai_lm import OpenAIModel\n",
    "from utils.together_lm import TogetherModel\n",
    "\n",
    "model_name = \"gpt-4-0314\"\n",
    "# model_name = \"gpt-35-turbo-0301\"\n",
    "# model_name = \"togethercomputer/llama-2-7b-chat\"\n",
    "# model_name = \"togethercomputer/llama-2-70b-chat\"\n",
    "\n",
    "if \"gpt\" in model_name:\n",
    "    model = OpenAIModel(model_name=model_name, cache_file=None, model_mode=\"chat_gpt\", api_type=\"azure\")\n",
    "else:\n",
    "    model = TogetherModel(model_name=model_name, cache_file=None)\n",
    "\n",
    "# output, response = model.generate(\"Hello, how are you?\")\n",
    "output, response = model.generate([{\"role\": \"user\", \"content\": \"Hello, how are you?\"}])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraphs: 78333\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "num_para = len(para_list)\n",
    "# num_para = 100\n",
    "random.seed(42)\n",
    "para_sample = random.sample(para_list, num_para)\n",
    "print(f\"Number of paragraphs: {len(para_sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_messages_list = []\n",
    "for para in para_sample:\n",
    "    # print(para)\n",
    "    title_section = para[\"title\"] if para[\"section\"] == \"\" else f\"{para['title']}; {para['section']}\"\n",
    "    content = para[\"content\"]\n",
    "    prompt = prompt_template.substitute(title=title_section, content=content)\n",
    "    para[\"input_messages\"] = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    # input_messages_list.append([{\"role\": \"user\", \"content\": prompt}])\n",
    "    # task_list.append(task)\n",
    "    # print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:05<09:29,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [07:11<00:00,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "output_path = f\"outputs/instructions.{model_name.split('/')[-1]}.{num_para}.txt\"\n",
    "output_list = []\n",
    "for i, para in enumerate(tqdm(para_sample)):\n",
    "    try:\n",
    "        input_messages = para[\"input_messages\"]\n",
    "        output, response = model._generate(input_messages)\n",
    "        output_list.append({\"instruction\": output, \"context\": {\"title\": para[\"title\"], \"section\": para[\"section\"], \"content\": para[\"content\"]}})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    if len(output_list) % 100 == 1:\n",
    "        save_jsonl(output_list, output_path)\n",
    "        print(f\"Number of outputs: {len(output_list)}\")\n",
    "save_jsonl(output_list, output_path)\n",
    "print(f\"Number of outputs: {len(output_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
