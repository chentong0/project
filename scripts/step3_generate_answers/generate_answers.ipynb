{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path(\"../../src\").resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.parser import load_prompt, load_jsonl, save_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI, I do not have feelings or emotions, but I am here to help you. How can I assist you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.openai_lm import OpenAIModel\n",
    "\n",
    "# model_name = \"gpt-4-0314\"\n",
    "model_name = \"gpt-35-turbo-0301\"\n",
    "\n",
    "model = OpenAIModel(model_name=model_name, cache_file=None, model_mode=\"chat_gpt\", api_type=\"azure\")\n",
    "model.load_model()\n",
    "output, response = model.generate([{\"role\": \"user\", \"content\": \"Hello, how are you?\"}])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instructions: 1000\n"
     ]
    }
   ],
   "source": [
    "prompt_path = \"prompt.txt\"\n",
    "inst_path = f\"../../scripts/step2_score_instruction/outputs/instructions_score.{model_name}.1000.txt\"\n",
    "\n",
    "prompt_template = load_prompt(prompt_path)\n",
    "inst_list = load_jsonl(inst_path)\n",
    "print(f\"Number of instructions: {len(inst_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instructions: 10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "num_inst = len(inst_list)\n",
    "# num_inst = 10\n",
    "# random.seed(42)\n",
    "# inst_list = random.sample(inst_list, num_inst)\n",
    "print(f\"Number of instructions: {len(inst_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for inst in inst_list:\n",
    "    # print(para)\n",
    "    context = inst[\"context\"]\n",
    "    instruction = inst[\"instruction\"]\n",
    "    prompt = prompt_template.substitute(instruction=instruction, context=context)\n",
    "    inst[\"input_messages\"] = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    # input_messages_list.append([{\"role\": \"user\", \"content\": prompt}])\n",
    "    # task_list.append(task)\n",
    "    # print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:05<00:51,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:37<00:00,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "output_path = f\"outputs/instructions_score.{model_name}.{num_inst}.txt\"\n",
    "output_list = []\n",
    "for i, inst in enumerate(tqdm(inst_list)):\n",
    "    try:\n",
    "        input_messages = inst[\"input_messages\"]\n",
    "        output, response = model._generate(input_messages, max_tokens=2048, temperature=0.0)\n",
    "        # match Analysis: (xxx)\\nScore: (xxx)\n",
    "        output_list.append({\"instruction_score\": inst[\"score\"], \"answer\": output, \"instruction\": inst[\"instruction\"], \"context\": inst[\"context\"]})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    if i % 100 == 0:\n",
    "        save_jsonl(output_list, output_path)\n",
    "        print(f\"Number of outputs: {len(output_list)}\")\n",
    "save_jsonl(output_list, output_path)\n",
    "print(f\"Number of outputs: {len(output_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
